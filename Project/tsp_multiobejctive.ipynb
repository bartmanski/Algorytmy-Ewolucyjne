{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Objective Traveling Salesman Problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definicja Problemu: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podstawowy problem TSP polega na optymalizacji ścieżki którą nasz handlaż podróżuje, której celem jest znalezienie takiej permutacji odwiedzanych przez niego miast, żeby ścieżka którą podróżuje była najkrótsza. Problem który w tej pracy zamierzam rozwiązać jest mocno powiązany z jego poprzednią wersją. Mianowicie dalej istnieje handlarz poruszający się po n-miastach jednak tym razem zamiast minimalizować tylko drogę musi również zadbać o inne rzeczy, np koszty,ślad-węglowy. Niestety mocno komplikuje to interpretacje 'optymalnego' rozwiązania o czym więcej w dalszej części. Podsumowując Multi-Objective TSP będzie polegał na znalezieniu grupy rozwiązań takich, że użytkownik jest w stanie wybrać które z celów są dla niego najważniejsze, czyli w rozwiązaniach powinny się znaleźć rozwiązania minimalizujące każdą z funkcji celu z osobna, ale również takie które biorą pod uwagę ich podzbiór w tym również takie uśredniające wszystkie cele. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROZWAŻANIA NAD OPTYMALNYM ROZWIAZANIEM:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli zastanowimy się chwilę nad powyższą definicją, ma ona pewien problem, mianowicie ciężko jest proównywać ze sobą rozwiązania. W przypadku jednej funkcji celu było to bardzo proste i polegało to jedynie na obliczaniu funkcji celu z pierwszego a potem drugiego rozwiązania i operowaniu na zwykłym porządku liczb rzeczywistych. W tym przypadku jednak nie można tak zrobić ponieważ gdybyśmy ekstapolowali tą logikę do $R^k$ gdzie k- liczebność funkcji celu, to bazowy porządek liniowy $R^k$ wprowadza nam hierarchię funkcji celu (narzuca która funkcja jest ważniejsza) tak, że pozostałe są przydatne jedynie do rozstrzygania 'remisów'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykład: mamy dwie funkcje cely f i g. w takim przypadku dla każdego osobnika x z populacji P tworzymy wektor (f(x),g(x)) należący do $R^2$.\n",
    "stosując jednak liniowy porządek $R^2$ gdy porównamy $x_1$ z $x_2$. To $ f(x_1) <  f(x_2)  \\Rightarrow  x_1 < x_2$,\n",
    "\n",
    "funkcje g rozpatrzymy dopiero gdy $ f(x_1) == f(x_2) $ bo wtedy $ g(x_1) < g(x_2) \\Rightarrow x_1 < x_2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WNIOSEK 1:\n",
    "\n",
    "Musimy więc wprowadzić inny porządek który pozwoli nam w jakiś sposób porównywać ze sobą poszczególne rozwiązania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WNIOSEK 2:\n",
    "\n",
    "Istnieje sytuacja w której niezależnie od porządku który chcemy ustalić, jesteśmy wstanie wybrać które rozwiązanie jest 'lepsze'.\n",
    "\n",
    "Gdy $x_1$ osiąga bardziej pożądane lub równe wyniki dla każdej funkcji celu od $x_2$ tak że conajmniej dla jednej z funkcji zachodzi $f(x_1)<f(x_2)$ (gdy szukamy minimum) wtedy możemy jednoznacznie powiedzieć że $x_1$ jest lepszym rozwiązaniem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea 1:\n",
    "Utworzenie funkcji $R^k \\to R$  i stosowanie standardowego porządku na R.\n",
    "\n",
    "Taką funkcją będzie norma $R^k$ dla znormalizowanych funcji. Dlaczego właśnie tak? Chcemy znormalizować funkcje ponieważ chcemy żeby rózne funkcje równie mocno na nią wpływały. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W poniższej implementacji $k=2$ i $n=10$ żeby czas sprawdzenia wszystkich kombinacji nie był zbut długi. Dane bedą dwoma macierzami symetrycznymi A,B takimi że $A_{i,j}$ - długość drogi z miasta i do j, natomiast $B_{i,j}$ - koszt drogi z miasta i do j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import data_mo_tsp\n",
    "\n",
    "\n",
    "'''\n",
    "# domyślnie każda krawędź jest ograniczona przez 100\n",
    "odleglosci,koszty = data_mo_tsp.generate_data(10,2)\n",
    "np.save('distances',odleglosci)\n",
    "np.save('costs',koszty)\n",
    "'''\n",
    "\n",
    "costs = np.load('costs.npy')\n",
    "odleglosci = np.load('distances.npy')\n",
    "\n",
    "\n",
    "def dist_goal_fun(perm):\n",
    "    curr_pos = 0\n",
    "    dist=0\n",
    "    for i in perm:\n",
    "        dist+=odleglosci[curr_pos][i]\n",
    "        curr_pos=i\n",
    "    dist+=odleglosci[curr_pos][0]\n",
    "    return dist\n",
    "\n",
    "def cost_goal_fun(perm):\n",
    "    curr_pos = 0\n",
    "    cost = 0\n",
    "    for i in perm:\n",
    "        cost+=costs[curr_pos][i]\n",
    "        curr_pos=i\n",
    "    cost+=costs[curr_pos][0]\n",
    "    return cost\n",
    "\n",
    "def eval(perm):\n",
    "    return np.array([dist_goal_fun(perm),cost_goal_fun(perm)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brute by dowiedzieć się jakie są 'optymalne' rozwiązania. (min kosztów , min trasa , średnie koszty średnia trasa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min z kosztów to: 282 obliczony przez kolejność: [3 2 1 4 8 6 5 7 9]\n",
      "min z dystansów to: 267 obliczony przez kolejność: [1 4 9 5 6 2 8 3 7]\n",
      "min z normy to: 475.47870614781476 obliczony przez kolejność: [7 5 6 2 1 4 3 8 9]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "#tylko 9 bo zawsze zaczynamy w 1\n",
    "indeksy = list(range(9))\n",
    "# koszt maksymalny  = max_krawedź (100) razy ilość miast (10)\n",
    "perm_min_cost = 1001\n",
    "cost_perm = None\n",
    "perm_min_dist = 1001\n",
    "dist_perm = None\n",
    "# max norm = pierwiastek sumy kwadratów max z cost i dist\n",
    "perm_min_norm = 2000\n",
    "norm_perm = None\n",
    "for i in itertools.permutations(indeksy):\n",
    "    perm = np.array(i)+1\n",
    "    vec2 = eval(perm)\n",
    "    norm = np.linalg.norm(vec2)\n",
    "    if(perm_min_dist>vec2[0]):\n",
    "        dist_perm=perm\n",
    "        perm_min_dist = vec2[0]\n",
    "    if(perm_min_cost>vec2[1]):\n",
    "        cost_perm=perm\n",
    "        perm_min_cost = vec2[1]\n",
    "    if(perm_min_norm>norm):\n",
    "        norm_perm=perm\n",
    "        perm_min_norm=norm\n",
    "\n",
    "print(f'min z kosztów to: {perm_min_cost} obliczony przez kolejność: {cost_perm}')\n",
    "print(f'min z dystansów to: {perm_min_dist} obliczony przez kolejność: {dist_perm}')\n",
    "print(f'min z normy to: {perm_min_norm} obliczony przez kolejność: {norm_perm}')\n",
    "np.save('opt_cost',perm_min_cost)\n",
    "np.save('opt_cost_perm',cost_perm)\n",
    "np.save('opt_dist',perm_min_dist)\n",
    "np.save('opt_dist_perm',dist_perm)\n",
    "np.save('opt_norm',perm_min_norm)\n",
    "np.save('opt_norm_perm',norm_perm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## przemyślenie po zobaczeniu wyników"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odrazu po tych wynikach spodziewamy się że jest coś nie tak, ponieważ każdy z nich zwrócił różne rozwiązanie (bardzo różne) więc prawdopodobnie norma nie jest dobrym wyznacznikiem porządku. (Istnieją sytuacje żeby była [kiedy opt wszystkich funkcji celu to ta sama permutacja] jednak w ogólności tak nie jest. Jednak i tak jest w czymś pomocna). Słowem komentarza jeszcze dlaczego nie normalizowaliśmy funkcji przed liczeniem normy, zrobiliśmy tak dlatego że max dla obu tych funkcji celu był by taki sam. Dodatkowo obie funkcje cely rosną w podobny sposób więc nie mamy problemu postaci drobna optymalizacja jednej funkcji spowoduje różniącą sie o znaczący rząd wielkości zmianę w drugiej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eksperyment 1 (Norma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-ta z kolei permutacja - [7 5 6 2 1 4 3 8 9] o wektorze wynikowym [324 348] osiągnęła norme 475.47870614781476\n",
      "1-ta z kolei permutacja - [7 5 6 2 1 4 3 8 9] o wektorze wynikowym [324 348] osiągnęła norme 475.47870614781476\n",
      "2-ta z kolei permutacja - [7 5 6 2 1 4 3 8 9] o wektorze wynikowym [324 348] osiągnęła norme 475.47870614781476\n",
      "3-ta z kolei permutacja - [9 8 3 4 1 2 6 5 7] o wektorze wynikowym [324 348] osiągnęła norme 475.47870614781476\n",
      "4-ta z kolei permutacja - [7 5 6 2 1 4 3 8 9] o wektorze wynikowym [324 348] osiągnęła norme 475.47870614781476\n",
      "5-ta z kolei permutacja - [9 8 3 4 1 2 6 5 7] o wektorze wynikowym [324 348] osiągnęła norme 475.47870614781476\n",
      "6-ta z kolei permutacja - [9 8 3 4 1 2 6 5 7] o wektorze wynikowym [324 348] osiągnęła norme 475.47870614781476\n",
      "7-ta z kolei permutacja - [9 8 3 4 1 2 6 5 7] o wektorze wynikowym [324 348] osiągnęła norme 475.47870614781476\n",
      "8-ta z kolei permutacja - [9 8 3 4 1 2 6 5 7] o wektorze wynikowym [324 348] osiągnęła norme 475.47870614781476\n",
      "9-ta z kolei permutacja - [9 8 3 4 1 2 6 5 7] o wektorze wynikowym [324 348] osiągnęła norme 475.47870614781476\n"
     ]
    }
   ],
   "source": [
    "class genetic_tsp_norm():\n",
    "    def __init__(self,eval_fun,perm_size,pop_size,mutation_propabilty):\n",
    "        self.eval_fun = eval_fun\n",
    "        self.perm_size=perm_size\n",
    "        self.pop_size = pop_size\n",
    "        self.mutation_propabilty = mutation_propabilty\n",
    "        # + 1 bo zawsze zaczynamy od 0 więc defakto mamy permutacje tylko 9 elemntów \n",
    "        self.population = np.array([np.random.permutation(perm_size-1) + 1 for i in range(pop_size)])\n",
    "        self.children = self.population.copy()\n",
    "\n",
    "    # weźmiemy standardowa mutacje dla tego problemu czyli transpozycje tablicy elemntów (losowanie 2 indexów i odwrócenie kolejności wszystkich elementów pomiędzy nimi)\n",
    "    def mutation(self):\n",
    "        for child_perm in self.children:\n",
    "            if(self.mutation_propabilty>np.random.uniform()):\n",
    "                a = np.random.choice(self.perm_size,2,False)\n",
    "                i,j = a.min(),a.max()\n",
    "                child_perm[i:j+1]=child_perm[i:j+1][::-1]\n",
    "                \n",
    "\n",
    "    def cross_over(self,parent1,parent2):\n",
    "        cutoff_1, cutoff_2 = np.sort(np.random.choice(self.perm_size, 2, replace=False))\n",
    "\n",
    "        def PMX_one_offspring(p1, p2):\n",
    "            offspring = np.zeros(len(p1), dtype=p1.dtype)\n",
    "\n",
    "            # Copy the mapping section (middle) from parent1\n",
    "            offspring[cutoff_1:cutoff_2] = p1[cutoff_1:cutoff_2]\n",
    "\n",
    "            # copy the rest from parent2 (provided it's not already there\n",
    "            for i in np.concatenate([np.arange(0,cutoff_1), np.arange(cutoff_2,len(p1))]):\n",
    "                candidate = p2[i]\n",
    "                while candidate in p1[cutoff_1:cutoff_2]: # allows for several successive mappings\n",
    "                    candidate = p2[np.where(p1 == candidate)[0][0]]\n",
    "                offspring[i] = candidate\n",
    "            return offspring\n",
    "\n",
    "        offspring1 = PMX_one_offspring(parent1, parent2)\n",
    "        #offspring2 = PMX_one_offspring(parent2, parent1)\n",
    "\n",
    "        return offspring1\n",
    "\n",
    "    def gen_kids(self):\n",
    "        children = []\n",
    "        for i in range(self.pop_size-len(self.population)):\n",
    "            p1_index,p2_index = np.random.choice(len(self.population),2,replace=False)\n",
    "            parent1,parent2 = self.population[p1_index],self.population[p2_index]\n",
    "            child = self.cross_over(parent1,parent2)\n",
    "            children.append(child)\n",
    "        self.children = np.array(children)\n",
    "\n",
    "    def eval_pop(self):\n",
    "        return np.argsort([np.linalg.norm(eval(perm)) for perm in self.population])\n",
    "\n",
    "    def step(self):\n",
    "        sorted=self.eval_pop()\n",
    "        self.population = self.population[sorted][:(self.pop_size//2)]\n",
    "        self.gen_kids()\n",
    "        self.mutation()\n",
    "        self.population = np.vstack((self.population,self.children))\n",
    "\n",
    "\n",
    "\n",
    "model = genetic_tsp_norm(eval,10,100,1)\n",
    "for i in range(1000):\n",
    "    model.step()\n",
    "\n",
    "for i in range(10):\n",
    "    perm = model.population[i]\n",
    "    vec2 = eval(model.population[i])\n",
    "    norm = np.linalg.norm(vec2)\n",
    "    print(f'{i}-ta z kolei permutacja - {perm} o wektorze wynikowym {vec2} osiągnęła norme {norm}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wnioski po eksperymencie 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widzimy że wyniki są nie najgorsze pod względem tego że algorytm znalazł optymalną norme, dodatkowo widzimy że wektor funkcji celu ma wyniki pośrednie, nie osiąga on żadnego z minimów ale za to każda z 2 wartości funkcji jest mniejsza niż wartość drugiej funkcji w permutacji minimalnej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wniosek: Do dlaszych obliczeń będziemy brali pod uwagę norme po to by znajdywać wyniki pośrednie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea 2:\n",
    "Zamiast wprowadzać jakiś porządek na R^k będziemy losowali jedną z funkcji i kolejną generacje tworzyli względem tej własnie.\n",
    "Dlaczego miało by działac, przy odpowiednio dużej liczbie iteracji każda z funkcji powinna mieć mniej więcej tyle samo generacji stworzonych względem samej siebie, z założeniem takim że przynajmniej fragment optymalnej populacji funkcji \"przeżywa\" ocenianie względem innej funkcji. (Jak można to sobie wyobrażać: mamy kilka punktów 'zbierzności' czyli punktów reprezentujących optymalne wartości względem którejś z funkcji, teraz startujemy w losowych rozmiar populacji miejscach, i z każdą iteracją punkty blisko punktu zbierzności związanego z wylosowaną funkcją powinny się do niego zbliżyć jednocześnie zostawiając przy życiu punkty blisko pozostałych funkcji) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eksperyment 1 (losowa funkcja ewaluacji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[534. 466.]\n",
      "100 osobnikow -----------------------\n",
      "Min dystans: 267 osiagniety przez: [7 3 4 9 5 6 2 8 1]\n",
      "Min koszt: 373 osiagniety przez: [9 5 6 4 8 1 2 3 7]\n",
      "Min norma: 624.0576896409498 osiagniety przez: [1 5 9 4 6 2 8 3 7]\n",
      "-------------------------------------\n",
      "[509. 491.]\n",
      "1000 osobnikow  --------------------------------------\n",
      "Min dystans: 267 osiagniety przez: [7 3 4 9 5 6 2 8 1]\n",
      "Min koszt: 342 osiagniety przez: [9 8 3 7 5 6 2 4 1]\n",
      "Min norma: 672.8803756983851 osiagniety przez: [1 3 8 7 4 9 5 6 2]\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class genetic_tsp_random_fun_eval():\n",
    "    def __init__(self,eval_fun,perm_size,pop_size,mutation_propabilty):\n",
    "        self.eval_fun = eval_fun\n",
    "        self.perm_size=perm_size\n",
    "        self.pop_size = pop_size\n",
    "        self.mutation_propabilty = mutation_propabilty\n",
    "        self.WhichIsEvaledMore = np.zeros(2)\n",
    "        # + 1 bo zawsze zaczynamy od 0 więc defakto mamy permutacje tylko 9 elemntów \n",
    "        self.population = np.array([np.random.permutation(perm_size-1) + 1 for i in range(pop_size)])\n",
    "        self.children = self.population.copy()\n",
    "\n",
    "    # weźmiemy standardowa mutacje dla tego problemu czyli transpozycje tablicy elemntów (losowanie 2 indexów i odwrócenie kolejności wszystkich elementów pomiędzy nimi)\n",
    "    def mutation(self):\n",
    "        for child_perm in self.children:\n",
    "            if(self.mutation_propabilty>np.random.uniform()):\n",
    "                a = np.random.choice(self.perm_size,2,False)\n",
    "                i,j = a.min(),a.max()\n",
    "                child_perm[i:j+1]=child_perm[i:j+1][::-1]\n",
    "                \n",
    "\n",
    "    def cross_over(self,parent1,parent2):\n",
    "        cutoff_1, cutoff_2 = np.sort(np.random.choice(self.perm_size, 2, replace=False))\n",
    "\n",
    "        def PMX_one_offspring(p1, p2):\n",
    "            offspring = np.zeros(len(p1), dtype=p1.dtype)\n",
    "\n",
    "            # Copy the mapping section (middle) from parent1\n",
    "            offspring[cutoff_1:cutoff_2] = p1[cutoff_1:cutoff_2]\n",
    "\n",
    "            # copy the rest from parent2 (provided it's not already there\n",
    "            for i in np.concatenate([np.arange(0,cutoff_1), np.arange(cutoff_2,len(p1))]):\n",
    "                candidate = p2[i]\n",
    "                while candidate in p1[cutoff_1:cutoff_2]: # allows for several successive mappings\n",
    "                    candidate = p2[np.where(p1 == candidate)[0][0]]\n",
    "                offspring[i] = candidate\n",
    "            return offspring\n",
    "\n",
    "        offspring1 = PMX_one_offspring(parent1, parent2)\n",
    "        #offspring2 = PMX_one_offspring(parent2, parent1)\n",
    "\n",
    "        return offspring1\n",
    "\n",
    "    def gen_kids(self):\n",
    "        children = []\n",
    "        for i in range(self.pop_size-len(self.population)):\n",
    "            p1_index,p2_index = np.random.choice(len(self.population),2,replace=False)\n",
    "            parent1,parent2 = self.population[p1_index],self.population[p2_index]\n",
    "            child = self.cross_over(parent1,parent2)\n",
    "            children.append(child)\n",
    "        self.children = np.array(children)\n",
    "\n",
    "    def eval_pop(self):\n",
    "        if(np.random.uniform()<0.5):\n",
    "            self.WhichIsEvaledMore[0]+=1\n",
    "            return np.argsort([eval(perm)[0] for perm in self.population])\n",
    "        else:\n",
    "            self.WhichIsEvaledMore[1]+=1\n",
    "            return np.argsort([eval(perm)[0] for perm in self.population])\n",
    "\n",
    "    def step(self):\n",
    "        sorted=self.eval_pop()\n",
    "        self.population = self.population[sorted][:(self.pop_size//2)]\n",
    "        self.gen_kids()\n",
    "        self.mutation()\n",
    "        self.population = np.vstack((self.population,self.children))\n",
    "\n",
    "model = genetic_tsp_random_fun_eval(eval,10,100,1)\n",
    "for i in range(1000):\n",
    "    model.step()\n",
    "\n",
    "print(model.WhichIsEvaledMore)\n",
    "min_dist=np.inf\n",
    "min_dist_perm=0\n",
    "min_cost=np.inf\n",
    "min_cost_perm=0\n",
    "min_norm=np.inf\n",
    "min_norm_perm=0\n",
    "for perm in model.population:\n",
    "    vec2= eval(perm)\n",
    "    if(vec2[0]<min_dist):\n",
    "        min_dist=vec2[0]\n",
    "        min_dist_perm=perm\n",
    "    if(vec2[1]<min_cost):\n",
    "        min_cost=vec2[1]\n",
    "        min_cost_perm=perm\n",
    "    if(vec2[0]<min_norm):\n",
    "        min_norm=np.linalg.norm(vec2)\n",
    "        min_norm_perm=perm\n",
    "print('100 osobnikow -----------------------')\n",
    "print(f'Min dystans: {min_dist} osiagniety przez: {min_dist_perm}')\n",
    "print(f'Min koszt: {min_cost} osiagniety przez: {min_cost_perm}')\n",
    "print(f'Min norma: {min_norm} osiagniety przez: {min_norm_perm}')\n",
    "print('-------------------------------------')\n",
    "model = genetic_tsp_random_fun_eval(eval,10,1000,1)\n",
    "for i in range(1000):\n",
    "    model.step()\n",
    "\n",
    "print(model.WhichIsEvaledMore)\n",
    "min_dist=np.inf\n",
    "min_dist_perm=0\n",
    "min_cost=np.inf\n",
    "min_cost_perm=0\n",
    "min_norm=np.inf\n",
    "min_norm_perm=0\n",
    "for perm in model.population:\n",
    "    vec2= eval(perm)\n",
    "    if(vec2[0]<min_dist):\n",
    "        min_dist=vec2[0]\n",
    "        min_dist_perm=perm\n",
    "    if(vec2[1]<min_cost):\n",
    "        min_cost=vec2[1]\n",
    "        min_cost_perm=perm\n",
    "    if(vec2[0]<min_norm):\n",
    "        min_norm=np.linalg.norm(vec2)\n",
    "        min_norm_perm=perm\n",
    "\n",
    "print('1000 osobnikow  --------------------------------------')\n",
    "print(f'Min dystans: {min_dist} osiagniety przez: {min_dist_perm}')\n",
    "print(f'Min koszt: {min_cost} osiagniety przez: {min_cost_perm}')\n",
    "print(f'Min norma: {min_norm} osiagniety przez: {min_norm_perm}')\n",
    "print('----------------------------------------------------------')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eksperyment 1 b) (losowa funkcja ewaluacji + norma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz powtórzymy eksperyment ale mozliwa do wylosowania bedzie jeszcze evaluacja po normie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[335. 333. 332.]\n",
      "100 osobnikow -----------------------\n",
      "Min dystans: 267 osiagniety przez: [1 8 2 6 5 9 4 3 7]\n",
      "Min koszt: 352 osiagniety przez: [9 7 5 6 8 2 1 4 3]\n",
      "Min norma: 556.2032002784593 osiagniety przez: [9 5 6 2 8 3 4 1 7]\n",
      "-------------------------------------\n",
      "[330. 331. 339.]\n",
      "1000 osobnikow  --------------------------------------\n",
      "Min dystans: 269 osiagniety przez: [7 3 4 9 5 6 8 2 1]\n",
      "Min koszt: 337 osiagniety przez: [7 5 6 2 1 4 8 3 9]\n",
      "Min norma: 558.5875043357129 osiagniety przez: [1 4 3 7 2 8 6 5 9]\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class genetic_tsp_random_fun_eval():\n",
    "    def __init__(self,eval_fun,perm_size,pop_size,mutation_propabilty):\n",
    "        self.eval_fun = eval_fun\n",
    "        self.perm_size=perm_size\n",
    "        self.pop_size = pop_size\n",
    "        self.mutation_propabilty = mutation_propabilty\n",
    "        self.WhichIsEvaledMore = np.zeros(3)\n",
    "        # + 1 bo zawsze zaczynamy od 0 więc defakto mamy permutacje tylko 9 elemntów \n",
    "        self.population = np.array([np.random.permutation(perm_size-1) + 1 for i in range(pop_size)])\n",
    "        self.children = self.population.copy()\n",
    "\n",
    "    # weźmiemy standardowa mutacje dla tego problemu czyli transpozycje tablicy elemntów (losowanie 2 indexów i odwrócenie kolejności wszystkich elementów pomiędzy nimi)\n",
    "    def mutation(self):\n",
    "        for child_perm in self.children:\n",
    "            if(self.mutation_propabilty>np.random.uniform()):\n",
    "                a = np.random.choice(self.perm_size,2,False)\n",
    "                i,j = a.min(),a.max()\n",
    "                child_perm[i:j+1]=child_perm[i:j+1][::-1]\n",
    "                \n",
    "\n",
    "    def cross_over(self,parent1,parent2):\n",
    "        cutoff_1, cutoff_2 = np.sort(np.random.choice(self.perm_size, 2, replace=False))\n",
    "\n",
    "        def PMX_one_offspring(p1, p2):\n",
    "            offspring = np.zeros(len(p1), dtype=p1.dtype)\n",
    "\n",
    "            # Copy the mapping section (middle) from parent1\n",
    "            offspring[cutoff_1:cutoff_2] = p1[cutoff_1:cutoff_2]\n",
    "\n",
    "            # copy the rest from parent2 (provided it's not already there\n",
    "            for i in np.concatenate([np.arange(0,cutoff_1), np.arange(cutoff_2,len(p1))]):\n",
    "                candidate = p2[i]\n",
    "                while candidate in p1[cutoff_1:cutoff_2]: # allows for several successive mappings\n",
    "                    candidate = p2[np.where(p1 == candidate)[0][0]]\n",
    "                offspring[i] = candidate\n",
    "            return offspring\n",
    "\n",
    "        offspring1 = PMX_one_offspring(parent1, parent2)\n",
    "        #offspring2 = PMX_one_offspring(parent2, parent1)\n",
    "\n",
    "        return offspring1\n",
    "\n",
    "    def gen_kids(self):\n",
    "        children = []\n",
    "        for i in range(self.pop_size-len(self.population)):\n",
    "            p1_index,p2_index = np.random.choice(len(self.population),2,replace=False)\n",
    "            parent1,parent2 = self.population[p1_index],self.population[p2_index]\n",
    "            child = self.cross_over(parent1,parent2)\n",
    "            children.append(child)\n",
    "        self.children = np.array(children)\n",
    "\n",
    "    def eval_pop(self):\n",
    "        zmienna_losowa=np.random.uniform()\n",
    "        if(zmienna_losowa<0.33):\n",
    "            self.WhichIsEvaledMore[0]+=1\n",
    "            return np.argsort([eval(perm)[0] for perm in self.population])\n",
    "        if(zmienna_losowa<0.66):\n",
    "            self.WhichIsEvaledMore[1]+=1\n",
    "            return np.argsort([eval(perm)[0] for perm in self.population])\n",
    "        else:\n",
    "            self.WhichIsEvaledMore[2]+=1\n",
    "            return np.argsort([np.linalg.norm(eval(perm)) for perm in self.population])\n",
    "\n",
    "    def step(self):\n",
    "        sorted=self.eval_pop()\n",
    "        self.population = self.population[sorted][:(self.pop_size//2)]\n",
    "        self.gen_kids()\n",
    "        self.mutation()\n",
    "        self.population = np.vstack((self.population,self.children))\n",
    "\n",
    "model = genetic_tsp_random_fun_eval(eval,10,100,1)\n",
    "for i in range(1000):\n",
    "    model.step()\n",
    "\n",
    "print(model.WhichIsEvaledMore)\n",
    "min_dist=np.inf\n",
    "min_dist_perm=0\n",
    "min_cost=np.inf\n",
    "min_cost_perm=0\n",
    "min_norm=np.inf\n",
    "min_norm_perm=0\n",
    "for perm in model.population:\n",
    "    vec2= eval(perm)\n",
    "    if(vec2[0]<min_dist):\n",
    "        min_dist=vec2[0]\n",
    "        min_dist_perm=perm\n",
    "    if(vec2[1]<min_cost):\n",
    "        min_cost=vec2[1]\n",
    "        min_cost_perm=perm\n",
    "    if(vec2[0]<min_norm):\n",
    "        min_norm=np.linalg.norm(vec2)\n",
    "        min_norm_perm=perm\n",
    "print('100 osobnikow -----------------------')\n",
    "print(f'Min dystans: {min_dist} osiagniety przez: {min_dist_perm}')\n",
    "print(f'Min koszt: {min_cost} osiagniety przez: {min_cost_perm}')\n",
    "print(f'Min norma: {min_norm} osiagniety przez: {min_norm_perm}')\n",
    "print('-------------------------------------')\n",
    "model = genetic_tsp_random_fun_eval(eval,10,1000,1)\n",
    "for i in range(1000):\n",
    "    model.step()\n",
    "\n",
    "print(model.WhichIsEvaledMore)\n",
    "min_dist=np.inf\n",
    "min_dist_perm=0\n",
    "min_cost=np.inf\n",
    "min_cost_perm=0\n",
    "min_norm=np.inf\n",
    "min_norm_perm=0\n",
    "for perm in model.population:\n",
    "    vec2= eval(perm)\n",
    "    if(vec2[0]<min_dist):\n",
    "        min_dist=vec2[0]\n",
    "        min_dist_perm=perm\n",
    "    if(vec2[1]<min_cost):\n",
    "        min_cost=vec2[1]\n",
    "        min_cost_perm=perm\n",
    "    if(vec2[0]<min_norm):\n",
    "        min_norm=np.linalg.norm(vec2)\n",
    "        min_norm_perm=perm\n",
    "\n",
    "print('1000 osobnikow  --------------------------------------')\n",
    "print(f'Min dystans: {min_dist} osiagniety przez: {min_dist_perm}')\n",
    "print(f'Min koszt: {min_cost} osiagniety przez: {min_cost_perm}')\n",
    "print(f'Min norma: {min_norm} osiagniety przez: {min_norm_perm}')\n",
    "print('----------------------------------------------------------') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wnioski z eksperymentu 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widzimy po wynikach Funkcje były losowane mniej więcej równomiernie jednak w wygenerowanych wynikach osiągamy tylko jedno minimum czyli nasze założenie było nie trafne, i osobniki po wylosowaniu innej fukncji niz tak którą optymalizują wymierają. Pomimo zwiekszenia populacji dalej ten problem istnieje. W teorii zwiększenie populacji powinno roziwazac ten problem ponieważ odrzucamy tylko pewną ilość osobnikow jednak najwyraźniej nie jest to na tyle skuteczne przy wylosowaniu tej samej funkcji kilka razy pod rząd. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By rozwiązać ten problem wprowadzę miejsca zarezerwowane, będą one polegaly na tym że w każdej populacji po ewaluacji w zgledem wybranej funkjci najpiwer wrzucamy do nowej populacji optima pozostałych funkcji a potem względem kolejności wylosowanej funkcji. Przy czym rezerwacja bedzie uwzgledniana tylko w populacji rodziców nie dzieci żeby nie utracić naszej zdolności przeszukiwania przestrzeni tylko żeby zachować pożądane osobniki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eksperyment 2 (miejsca zarezerwowane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[321. 350. 329.]\n",
      "100 osobnikow -----------------------\n",
      "Min dystans: 267 osiagniety przez: [7 3 4 9 5 6 2 8 1]\n",
      "Min koszt: 282 osiagniety przez: [9 7 5 6 8 4 1 2 3]\n",
      "Min norma: 475.47870614781476 osiagniety przez: [7 5 6 2 1 4 3 8 9]\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class genetic_tsp_random_fun_eval_reserved():\n",
    "    def __init__(self,eval_fun,perm_size,pop_size,mutation_propabilty,reservation_size=10):\n",
    "        self.eval_fun = eval_fun\n",
    "        self.perm_size=perm_size\n",
    "        self.pop_size = pop_size\n",
    "        self.mutation_propabilty = mutation_propabilty\n",
    "        self.WhichIsEvaledMore = np.zeros(3)\n",
    "        self.reservation_size = reservation_size\n",
    "        # + 1 bo zawsze zaczynamy od 0 więc defakto mamy permutacje tylko 9 elemntów \n",
    "        self.population = np.array([np.random.permutation(perm_size-1) + 1 for i in range(pop_size)])\n",
    "        self.children = self.population.copy()\n",
    "\n",
    "    # weźmiemy standardowa mutacje dla tego problemu czyli transpozycje tablicy elemntów (losowanie 2 indexów i odwrócenie kolejności wszystkich elementów pomiędzy nimi)\n",
    "    def mutation(self):\n",
    "        for child_perm in self.children:\n",
    "            if(self.mutation_propabilty>np.random.uniform()):\n",
    "                a = np.random.choice(self.perm_size,2,False)\n",
    "                i,j = a.min(),a.max()\n",
    "                child_perm[i:j+1]=child_perm[i:j+1][::-1]\n",
    "                \n",
    "\n",
    "    def cross_over(self,parent1,parent2):\n",
    "        cutoff_1, cutoff_2 = np.sort(np.random.choice(self.perm_size, 2, replace=False))\n",
    "\n",
    "        def PMX_one_offspring(p1, p2):\n",
    "            offspring = np.zeros(len(p1), dtype=p1.dtype)\n",
    "\n",
    "            # Copy the mapping section (middle) from parent1\n",
    "            offspring[cutoff_1:cutoff_2] = p1[cutoff_1:cutoff_2]\n",
    "\n",
    "            # copy the rest from parent2 (provided it's not already there\n",
    "            for i in np.concatenate([np.arange(0,cutoff_1), np.arange(cutoff_2,len(p1))]):\n",
    "                candidate = p2[i]\n",
    "                while candidate in p1[cutoff_1:cutoff_2]: # allows for several successive mappings\n",
    "                    candidate = p2[np.where(p1 == candidate)[0][0]]\n",
    "                offspring[i] = candidate\n",
    "            return offspring\n",
    "\n",
    "        offspring1 = PMX_one_offspring(parent1, parent2)\n",
    "        #offspring2 = PMX_one_offspring(parent2, parent1)\n",
    "\n",
    "        return offspring1\n",
    "\n",
    "    def gen_kids(self):\n",
    "        children = []\n",
    "        for i in range(self.pop_size-len(self.population)):\n",
    "            p1_index,p2_index = np.random.choice(len(self.population),2,replace=False)\n",
    "            parent1,parent2 = self.population[p1_index],self.population[p2_index]\n",
    "            child = self.cross_over(parent1,parent2)\n",
    "            children.append(child)\n",
    "        self.children = np.array(children)\n",
    "\n",
    "    def eval_pop(self):\n",
    "        return np.array([self.eval_fun(perm) for perm in self.population])\n",
    "\n",
    "    def step(self):\n",
    "        pop_evaluation=self.eval_pop()\n",
    "        sorted0 = np.argsort(pop_evaluation[:, 0]) # by pop_evaluation[i][0]\n",
    "        sorted1 = np.argsort(pop_evaluation[:, 1]) # by pop_evaluation[i][1]\n",
    "        sortednorm = np.argsort(np.linalg.norm(pop_evaluation,axis=1)) # by norm  of pop_evaluation[i]\n",
    "        \n",
    "        top0 = self.population[sorted0[:self.reservation_size]]\n",
    "        top1 = self.population[sorted1[:self.reservation_size]]\n",
    "        topnorm = self.population[sortednorm[:self.reservation_size]]\n",
    "\n",
    "        reserved = np.vstack((top0,top1,topnorm))\n",
    "        remaining_needed = self.pop_size // 2 - len(reserved)\n",
    "\n",
    "        new_pop = []\n",
    "        wylosowany=np.random.choice([0,1,2])\n",
    "        self.WhichIsEvaledMore[wylosowany]+=1\n",
    "        order_by_rand_fun = [sorted0,sorted1,sortednorm][wylosowany]\n",
    "        for i in range(remaining_needed):\n",
    "            new_pop.append(self.population[order_by_rand_fun[i+self.reservation_size]])\n",
    "\n",
    "        new_pop= np.array(new_pop)\n",
    "        self.population = np.vstack((reserved,new_pop))\n",
    "        self.gen_kids()\n",
    "        self.mutation()\n",
    "        self.population = np.vstack((self.population,self.children))\n",
    "\n",
    "\n",
    "# reserved * ilość funkcji < popsize//2  \n",
    "model = genetic_tsp_random_fun_eval_reserved(eval,10,100,1)\n",
    "for i in range(1000):\n",
    "    model.step()\n",
    "\n",
    "print(model.WhichIsEvaledMore)\n",
    "min_dist=np.inf\n",
    "min_dist_perm=0\n",
    "min_cost=np.inf\n",
    "min_cost_perm=0\n",
    "min_norm=np.inf\n",
    "min_norm_perm=0\n",
    "for perm in model.population:\n",
    "    vec2= eval(perm)\n",
    "    if(vec2[0]<min_dist):\n",
    "        min_dist=vec2[0]\n",
    "        min_dist_perm=perm\n",
    "    if(vec2[1]<min_cost):\n",
    "        min_cost=vec2[1]\n",
    "        min_cost_perm=perm\n",
    "    if(np.linalg.norm(vec2)<min_norm):\n",
    "        min_norm=np.linalg.norm(vec2)\n",
    "        min_norm_perm=perm\n",
    "print('100 osobnikow -----------------------')\n",
    "print(f'Min dystans: {min_dist} osiagniety przez: {min_dist_perm}')\n",
    "print(f'Min koszt: {min_cost} osiagniety przez: {min_cost_perm}')\n",
    "print(f'Min norma: {min_norm} osiagniety przez: {min_norm_perm}')\n",
    "print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widzimy eksperyment zakończył sie sukcesem ponieważ znaleźliśmy optima wszystkich z naszych podgrup, czyli optimum kosztu optimum dystansu i śrenia wartość między nimi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100) (100, 100)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def parse_tsp_to_matrix(file_path):\n",
    "    # Read the TSP file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Initialize variables\n",
    "    dimension = 0\n",
    "    edge_weights = []\n",
    "    \n",
    "    # Read relevant data from the file\n",
    "    for line in lines:\n",
    "        if line.startswith('DIMENSION'):\n",
    "            dimension = int(line.split(':')[1].strip())\n",
    "        elif line.startswith('EDGE_WEIGHT_SECTION'):\n",
    "            break\n",
    "    \n",
    "    # Extract the edge weights (from the next lines after EDGE_WEIGHT_SECTION)\n",
    "    for line in lines[lines.index('EDGE_WEIGHT_SECTION\\n') + 1:]:\n",
    "        if line.strip():  # Avoid empty lines\n",
    "            edge_weights.extend(map(int, line.split()))\n",
    "    \n",
    "    # Now create the symmetric matrix\n",
    "    matrix = np.zeros((dimension, dimension), dtype=int)\n",
    "    \n",
    "    # Fill the upper triangular matrix first\n",
    "    idx = 0\n",
    "    for i in range(dimension):\n",
    "        for j in range(i + 1, dimension):\n",
    "            matrix[i][j] = edge_weights[idx]\n",
    "            matrix[j][i] = edge_weights[idx]\n",
    "            idx += 1\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "odleglosci1 = parse_tsp_to_matrix('randomA100.tsp')\n",
    "costs1 = parse_tsp_to_matrix('randomB100.tsp')\n",
    "\n",
    "print(odleglosci1.shape , costs1.shape)\n",
    "\n",
    "\n",
    "def dist_goal_fun1(perm):\n",
    "    curr_pos = 0\n",
    "    dist=0\n",
    "    for i in perm:\n",
    "        dist+=odleglosci1[curr_pos][i]\n",
    "        curr_pos=i\n",
    "    dist+=odleglosci1[curr_pos][0]\n",
    "    return dist\n",
    "\n",
    "def cost_goal_fun1(perm):\n",
    "    curr_pos = 0\n",
    "    cost = 0\n",
    "    for i in perm:\n",
    "        cost+=costs1[curr_pos][i]\n",
    "        curr_pos=i\n",
    "    cost+=costs1[curr_pos][0]\n",
    "    return cost\n",
    "\n",
    "def eval1(perm):\n",
    "    return np.array([dist_goal_fun1(perm),cost_goal_fun1(perm)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eksperyment 3 (wieksze dane z internetu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3306. 3350. 3344.]\n",
      "100 osobnikow -----------------------\n",
      "Min dystans: 11498 osiagniety przez: [58 26 53 59 29 14 54 62 22 82 83 41 20 80 60 46 93 76 90 91 45 18 37 10\n",
      " 21 65 95 87 43 81 40 84 66 28 57  6 13 27 55 99 49 32  2 96 98 24 67  7\n",
      " 15 31 63 44 89 92 64 48 97 85 78  5 11 23 47 79 39 19  9  4 75 51 25 61\n",
      " 30 73 36 42 50 68 70 72 86 88 56 52 12 94 16 33  8 17 35 71 34 69 74 38\n",
      " 77  3  1]\n",
      "Min koszt: 12317 osiagniety przez: [97 48 64 92 89 44 63 60 80 77 38 74 69 34  8 17 35 71 57 28 94 12 45 91\n",
      " 90 79 59 53 26 73 30 61 99 49 65  2  5 11 23 47 95 87 32 82 83 41 20 58\n",
      " 88 86 72 66 50 56 16 33  6 13 27 55 22 62 54 14 29 39 19  9  4 51 25 75\n",
      " 98 96 78 85 42 36 52 18 37 10 21 43 81 40 84 68 70  1  3 24 67  7 15 31\n",
      " 46 93 76]\n",
      "Min norma: 25595.55977117906 osiagniety przez: [97 48 64 92 89 44 63 60 80 77 38 74 69 34 53 26 58 20 41 83 82  8 17 35\n",
      " 71 57 28 66 98 75  4  9 19 39 79 73 90 91 45 18 37 10 21 32 49 99 55 27\n",
      " 13  6 33 16 94 12 52 56 88 86 72 70 68 50 65 95 87 43 81 40 84 96 78 85\n",
      " 42 36 76 93 46 31 15  7 67 24 51 25 61 30 47 23 22 62 54 14 29 59 11  5\n",
      "  2  3  1]\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = genetic_tsp_random_fun_eval_reserved(eval1,100,1000,1,100)\n",
    "for i in range(10000):\n",
    "    model.step()\n",
    "\n",
    "print(model.WhichIsEvaledMore)\n",
    "min_dist=np.inf\n",
    "min_dist_perm=0\n",
    "min_cost=np.inf\n",
    "min_cost_perm=0\n",
    "min_norm=np.inf\n",
    "min_norm_perm=0\n",
    "for perm in model.population:\n",
    "    vec2= eval1(perm)\n",
    "    if(vec2[0]<min_dist):\n",
    "        min_dist=vec2[0]\n",
    "        min_dist_perm=perm\n",
    "    if(vec2[1]<min_cost):\n",
    "        min_cost=vec2[1]\n",
    "        min_cost_perm=perm\n",
    "    if(np.linalg.norm(vec2)<min_norm):\n",
    "        min_norm=np.linalg.norm(vec2)\n",
    "        min_norm_perm=perm\n",
    "print('100 osobnikow -----------------------')\n",
    "print(f'Min dystans: {min_dist} osiagniety przez: {min_dist_perm}')\n",
    "print(f'Min koszt: {min_cost} osiagniety przez: {min_cost_perm}')\n",
    "print(f'Min norma: {min_norm} osiagniety przez: {min_norm_perm}')\n",
    "print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Można zauważyć że optima nie zostały osiągnięte jednak nie jesteśmy daleko od nich, spójrzmy jeszcze na wyniki ogólne całej populacji żeby móc sprawdzić czy faktycznie odtrzymaliśmy cale spektrum rozwiązań o które nam chodziło"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dystans: 11498 koszt: 51694\n",
      " dystans: 11689 koszt: 40144\n",
      " dystans: 11780 koszt: 40436\n",
      " dystans: 11841 koszt: 40868\n",
      " dystans: 11846 koszt: 39703\n",
      " dystans: 11937 koszt: 43159\n",
      " dystans: 12278 koszt: 35798\n",
      " dystans: 12306 koszt: 44627\n",
      " dystans: 12376 koszt: 46770\n",
      " dystans: 12383 koszt: 36689\n",
      " dystans: 12425 koszt: 39486\n",
      " dystans: 12488 koszt: 45911\n",
      " dystans: 12491 koszt: 45517\n",
      " dystans: 12491 koszt: 45517\n",
      " dystans: 12585 koszt: 35657\n",
      " dystans: 12585 koszt: 35657\n",
      " dystans: 12588 koszt: 40491\n",
      " dystans: 12599 koszt: 43243\n",
      " dystans: 12604 koszt: 38923\n",
      " dystans: 12671 koszt: 42730\n"
     ]
    }
   ],
   "source": [
    "for perm in model.population[:20]:\n",
    "    vec2= eval1(perm)\n",
    "    print(f' dystans: {vec2[0]} koszt: {vec2[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wniosek z eksperymentu 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przeglądając tylko wyniki kilku pierwszych próbek możemy zaobsrewować coś niepożądanego, mianowicie w końcowej populacji znajdują sie rozwiązania których nie powinno tam nie być tzn rozwiązania zdominowane, czyli takie które osiągają gorsze wyniki od innego osobnika na każdej możliwej funkcji ewaluacyjnej. Jeśli w jakiś sposób udalo by się ograniczyć takie osobniki otrzymali byśmy faktyczne spektrum rozwiązań o które nam chodziło, jednocześnie poprawiając efektywność algorytmu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dywagacje nad problemem generowania zdominowancyh rozwiązań"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zagadnienie 1 (Czy zdominowane rozwiązania mają wpływ na wynik algorytmu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zauważmy że w algorytmach genetycznych przeszukujemy przestrzeń dyskretnie, tzn wybieramy losowych reprezentantów danego wycinka przestrzeni i na ich podstawie oceniamy całą przestrzeń. Ma to znaczenie ponieważ gdybyśmy usunęli z każdej populacji zdominowane osobniki mogło by się okazać że odcieliśmy znaczącą część przestrzeni, ponieważ oceniali byśmy daną mutacje po osobnikach nie reprezentatywnych, w szeczgólności przy znalezieniu optimów lokalnych dla każdej funkcji ciężko było by z nich wyjść, ponieważ \"najpierw musilibysmy iść troche pod górkę żeby móc zejść jeszcze niżej\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zgadanienie 2 (Jak optymalnie sprawdzać czy rozwiązanie jest zdominowane czy nie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niestety jeśli moje rozumowanie jest poprawne nie da sie tego zrobic inaczej niz sprawdzic każdy z każdym czyli w O($ n^2 $) ponieważ załóżmy że nie musimy sprawdzać ze sobą jakieś pary permutacji p i q. Może się okazać że oba są nie dominowane przez żadne inną permutacje jednak p dominuje q."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zagadnienie 3 (Jak poradzić sobie z generacją nowej populacji tak aby była jak najmniej zdominowana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nie możemy zagwarantować żeby ilości nie zdominowanaych rozwiązań ponieważ w szczególności może istnieć tylko jedno. Jednak chcieli byśmy mieć w naszej populacji jak najmniej zdominowane rozwiązania ponieważ zdominowane rozwiązania heurystycznie dążą do tego samego optimum, a takowe wystarczy że znajdziemy raz. Pomysł jest więc taki zeby do nowej populacji brać jako pierwsze rozwiązania nie zdominowane takie. Nazwijmy cały ich zbiór P1. Następnie jeśli będzie to potrzebne będziemy brali te rozwiązania które były dominowane przez rozwiązania z grupy P1. Takie rozwiązania nawiemy P2. Taki krok będziemy iterować aż znajdziemy całą populacje. Taki podział na grupy nazywa się rozkładem Pareto.\n",
    "\n",
    "Ale jak to się ma do szukania optimów danych funkcji, zauważmy że gdy rozwiązanie jest w P1 to jest aktualnym optimum w którejś funkcji więc i tak chcieli bysmy żeby znalazło się w populacji, co do rozwiązań z dalszych grup niż P1 są to rozwiązania najbardziej odkrywacze pod względem szukanych przez nas odpowiedzi ponieważ, gdyby coś było zdominowane przez dużo osobników oznacza że w kolejnej populacji dzieci stworzone z tego osobnika prawdopodobnie znowu będą zdominowane przez dzieci osobników które go wcześniej dominowały."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea 3:\n",
    "Zastosujemy rozkład Pareto na populacji, następnie biorąc do nowej populacji osobniki w kolejności grup w jakich się znajdują aż zapełnimi połowę całej populacji następnie wygenerujemy dzieci od tej populacji w sposób tożsamy z poprzednimi algorytmami, i zaczniemy evaluacje od początku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "dist: 267   cost: 509\n",
      "dist: 269   cost: 500\n",
      "dist: 274   cost: 451\n",
      "dist: 276   cost: 429\n",
      "dist: 297   cost: 415\n",
      "dist: 309   cost: 381\n",
      "dist: 316   cost: 380\n",
      "dist: 324   cost: 348\n",
      "dist: 349   cost: 334\n",
      "dist: 388   cost: 316\n",
      "dist: 433   cost: 302\n",
      "dist: 468   cost: 301\n",
      "dist: 478   cost: 298\n",
      "dist: 495   cost: 292\n",
      "dist: 512   cost: 290\n",
      "dist: 523   cost: 289\n",
      "dist: 545   cost: 282\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "class genetic_tsp_pareto():\n",
    "    def __init__(self,eval_fun,perm_size,pop_size,mutation_propabilty):\n",
    "        self.eval_fun = eval_fun\n",
    "        self.perm_size=perm_size\n",
    "        self.pop_size = pop_size\n",
    "        self.mutation_propabilty = mutation_propabilty\n",
    "        self.WhichIsEvaledMore = np.zeros(3)\n",
    "        # + 1 bo zawsze zaczynamy od 0 więc defakto mamy permutacje tylko 9 elemntów \n",
    "        self.population = np.array([np.random.permutation(perm_size-1) + 1 for i in range(pop_size)])\n",
    "        self.children = self.population.copy()\n",
    "\n",
    "    # weźmiemy standardowa mutacje dla tego problemu czyli transpozycje tablicy elemntów (losowanie 2 indexów i odwrócenie kolejności wszystkich elementów pomiędzy nimi)\n",
    "    def mutation(self):\n",
    "        for child_perm in self.children:\n",
    "            if(self.mutation_propabilty>np.random.uniform()):\n",
    "                a = np.random.choice(self.perm_size,2,False)\n",
    "                i,j = a.min(),a.max()\n",
    "                child_perm[i:j+1]=child_perm[i:j+1][::-1]\n",
    "                \n",
    "\n",
    "    def cross_over(self,parent1,parent2):\n",
    "        cutoff_1, cutoff_2 = np.sort(np.random.choice(self.perm_size, 2, replace=False))\n",
    "\n",
    "        def PMX_one_offspring(p1, p2):\n",
    "            offspring = np.zeros(len(p1), dtype=p1.dtype)\n",
    "\n",
    "            # Copy the mapping section (middle) from parent1\n",
    "            offspring[cutoff_1:cutoff_2] = p1[cutoff_1:cutoff_2]\n",
    "\n",
    "            # copy the rest from parent2 (provided it's not already there\n",
    "            for i in np.concatenate([np.arange(0,cutoff_1), np.arange(cutoff_2,len(p1))]):\n",
    "                candidate = p2[i]\n",
    "                while candidate in p1[cutoff_1:cutoff_2]: # allows for several successive mappings\n",
    "                    candidate = p2[np.where(p1 == candidate)[0][0]]\n",
    "                offspring[i] = candidate\n",
    "            return offspring\n",
    "\n",
    "        offspring1 = PMX_one_offspring(parent1, parent2)\n",
    "        #offspring2 = PMX_one_offspring(parent2, parent1)\n",
    "\n",
    "        return offspring1\n",
    "\n",
    "    def gen_kids(self):\n",
    "        children = []\n",
    "        for i in range(self.pop_size-len(self.population)):\n",
    "            p1_index,p2_index = np.random.choice(len(self.population),2,replace=False)\n",
    "            parent1,parent2 = self.population[p1_index],self.population[p2_index]\n",
    "            child = self.cross_over(parent1,parent2)\n",
    "            children.append(child)\n",
    "        self.children = np.array(children)\n",
    "\n",
    "    def pareto_fronts(self):\n",
    "        # wywalenie duplikatów\n",
    "        self.population = np.unique(self.population,axis=0)\n",
    "        pareto_fronts=[[] for i in range(len(self.population))]\n",
    "        how_many_many_dom_u = dict()\n",
    "        who_do_u_dom = dict()\n",
    "        evaluated=dict()\n",
    "\n",
    "        # innit wszystkich dictów\n",
    "        for perm in self.population:\n",
    "            how_many_many_dom_u[tuple(perm)]=0\n",
    "            who_do_u_dom[tuple(perm)]=[]\n",
    "            evaluated[tuple(perm)]=self.eval_fun(perm)\n",
    "\n",
    "        # liczenie kto kogo dominuje\n",
    "        for perm1,perm2 in it.combinations(self.population,2):\n",
    "            evaluated1 = evaluated[tuple(perm1)]\n",
    "            evaluated2 = evaluated[tuple(perm2)]\n",
    "            if( evaluated1[0]>evaluated2[0] and evaluated1[1]>evaluated2[1]):\n",
    "                how_many_many_dom_u[tuple(perm1)]+=1\n",
    "                who_do_u_dom[tuple(perm2)].append(tuple(perm1))\n",
    "            elif(evaluated1[0]<=evaluated2[0] and evaluated1[1]<=evaluated2[1]):\n",
    "                how_many_many_dom_u[tuple(perm2)]+=1\n",
    "                who_do_u_dom[tuple(perm1)].append(tuple(perm2))\n",
    "\n",
    "        selected = 0\n",
    "        front_num=0\n",
    "        while (selected != len(self.population)):\n",
    "            for perm in self.population:\n",
    "                if(how_many_many_dom_u[tuple(perm)]==0):\n",
    "                    pareto_fronts[front_num].append(perm)\n",
    "                    how_many_many_dom_u[tuple(perm)]=-1\n",
    "                    selected+=1\n",
    "            for key in pareto_fronts[front_num]:\n",
    "                for perm in who_do_u_dom[tuple(key)]:\n",
    "                    how_many_many_dom_u[tuple(perm)]-=1 \n",
    "            front_num+=1\n",
    "        return pareto_fronts\n",
    "\n",
    "    def step(self):\n",
    "        pareto_fronts = self.pareto_fronts()\n",
    "        taken=0\n",
    "        self.population=[]\n",
    "        for front in pareto_fronts:\n",
    "            for perm in front:\n",
    "                if(taken==self.pop_size//2):\n",
    "                    break\n",
    "                else:\n",
    "                    self.population.append(perm)\n",
    "                    taken+=1\n",
    "        self.population=np.array(self.population)\n",
    "        self.gen_kids()\n",
    "        self.mutation()\n",
    "        self.population = np.vstack((self.population,self.children))\n",
    "\n",
    "\n",
    "# reserved * ilość funkcji < popsize//2  \n",
    "model = genetic_tsp_pareto(eval,10,100,1)\n",
    "for i in range(1000):\n",
    "    model.step()\n",
    "\n",
    "min_dist=np.inf\n",
    "min_dist_perm=0\n",
    "min_cost=np.inf\n",
    "min_cost_perm=0\n",
    "min_norm=np.inf\n",
    "min_norm_perm=0\n",
    "wazne = model.pareto_fronts()[0]\n",
    "wazne_sorted = sorted(wazne, key=lambda perm: model.eval_fun(list(perm))[0])\n",
    "print(len(wazne))\n",
    "for perm in wazne_sorted:\n",
    "    vec2= eval(perm)\n",
    "    if(vec2[0]<min_dist):\n",
    "        min_dist=vec2[0]\n",
    "        min_dist_perm=perm\n",
    "    if(vec2[1]<min_cost):\n",
    "        min_cost=vec2[1]\n",
    "        min_cost_perm=perm\n",
    "    if(np.linalg.norm(vec2)<min_norm):\n",
    "        min_norm=np.linalg.norm(vec2)\n",
    "        min_norm_perm=perm\n",
    "    print(f'dist: {vec2[0]}   cost: {vec2[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 osobnikow -----------------------\n",
      "Min dystans: 267 osiagniety przez: [1 4 9 5 6 2 8 3 7]\n",
      "Min koszt: 282 osiagniety przez: [3 2 1 4 8 6 5 7 9]\n",
      "Min norma: 475.47870614781476 osiagniety przez: [7 5 6 2 1 4 3 8 9]\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('100 osobnikow -----------------------')\n",
    "print(f'Min dystans: {min_dist} osiagniety przez: {min_dist_perm}')\n",
    "print(f'Min koszt: {min_cost} osiagniety przez: {min_cost_perm}')\n",
    "print(f'Min norma: {min_norm} osiagniety przez: {min_norm_perm}')\n",
    "print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 112\u001b[0m\n\u001b[0;32m    110\u001b[0m model \u001b[38;5;241m=\u001b[39m genetic_tsp_pareto(eval1,\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m1000\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m--> 112\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m min_dist\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m    115\u001b[0m min_dist_perm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[56], line 93\u001b[0m, in \u001b[0;36mgenetic_tsp_pareto.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 93\u001b[0m     pareto_fronts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpareto_fronts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     taken\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation\u001b[38;5;241m=\u001b[39m[]\n",
      "Cell \u001b[1;32mIn[56]\u001b[0m, in \u001b[0;36mgenetic_tsp_pareto.pareto_fronts\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "class genetic_tsp_pareto():\n",
    "    def __init__(self,eval_fun,perm_size,pop_size,mutation_propabilty):\n",
    "        self.eval_fun = eval_fun\n",
    "        self.perm_size=perm_size\n",
    "        self.pop_size = pop_size\n",
    "        self.mutation_propabilty = mutation_propabilty\n",
    "        self.WhichIsEvaledMore = np.zeros(3)\n",
    "        # + 1 bo zawsze zaczynamy od 0 więc defakto mamy permutacje tylko 9 elemntów \n",
    "        self.population = np.array([np.random.permutation(perm_size-1) + 1 for i in range(pop_size)])\n",
    "        self.children = self.population.copy()\n",
    "\n",
    "    # weźmiemy standardowa mutacje dla tego problemu czyli transpozycje tablicy elemntów (losowanie 2 indexów i odwrócenie kolejności wszystkich elementów pomiędzy nimi)\n",
    "    def mutation(self):\n",
    "        for child_perm in self.children:\n",
    "            if(self.mutation_propabilty>np.random.uniform()):\n",
    "                a = np.random.choice(self.perm_size,2,False)\n",
    "                i,j = a.min(),a.max()\n",
    "                child_perm[i:j+1]=child_perm[i:j+1][::-1]\n",
    "                \n",
    "\n",
    "    def cross_over(self,parent1,parent2):\n",
    "        cutoff_1, cutoff_2 = np.sort(np.random.choice(self.perm_size, 2, replace=False))\n",
    "\n",
    "        def PMX_one_offspring(p1, p2):\n",
    "            offspring = np.zeros(len(p1), dtype=p1.dtype)\n",
    "\n",
    "            # Copy the mapping section (middle) from parent1\n",
    "            offspring[cutoff_1:cutoff_2] = p1[cutoff_1:cutoff_2]\n",
    "\n",
    "            # copy the rest from parent2 (provided it's not already there\n",
    "            for i in np.concatenate([np.arange(0,cutoff_1), np.arange(cutoff_2,len(p1))]):\n",
    "                candidate = p2[i]\n",
    "                while candidate in p1[cutoff_1:cutoff_2]: # allows for several successive mappings\n",
    "                    candidate = p2[np.where(p1 == candidate)[0][0]]\n",
    "                offspring[i] = candidate\n",
    "            return offspring\n",
    "\n",
    "        offspring1 = PMX_one_offspring(parent1, parent2)\n",
    "        #offspring2 = PMX_one_offspring(parent2, parent1)\n",
    "\n",
    "        return offspring1\n",
    "\n",
    "    def gen_kids(self):\n",
    "        children = []\n",
    "        for i in range(self.pop_size-len(self.population)):\n",
    "            p1_index,p2_index = np.random.choice(len(self.population),2,replace=False)\n",
    "            parent1,parent2 = self.population[p1_index],self.population[p2_index]\n",
    "            child = self.cross_over(parent1,parent2)\n",
    "            children.append(child)\n",
    "        self.children = np.array(children)\n",
    "\n",
    "    def pareto_fronts(self):\n",
    "        # wywalenie duplikatów\n",
    "        self.population = np.unique(self.population,axis=0)\n",
    "        pareto_fronts=[[] for i in range(len(self.population))]\n",
    "        how_many_many_dom_u = dict()\n",
    "        who_do_u_dom = dict()\n",
    "        evaluated=dict()\n",
    "\n",
    "        # innit wszystkich dictów\n",
    "        for perm in self.population:\n",
    "            how_many_many_dom_u[tuple(perm)]=0\n",
    "            who_do_u_dom[tuple(perm)]=[]\n",
    "            evaluated[tuple(perm)]=self.eval_fun(perm)\n",
    "\n",
    "        # liczenie kto kogo dominuje\n",
    "        for perm1,perm2 in it.combinations(self.population,2):\n",
    "            evaluated1 = evaluated[tuple(perm1)]\n",
    "            evaluated2 = evaluated[tuple(perm2)]\n",
    "            if( evaluated1[0]>evaluated2[0] and evaluated1[1]>evaluated2[1]):\n",
    "                how_many_many_dom_u[tuple(perm1)]+=1\n",
    "                who_do_u_dom[tuple(perm2)].append(tuple(perm1))\n",
    "            elif(evaluated1[0]<=evaluated2[0] and evaluated1[1]<=evaluated2[1]):\n",
    "                how_many_many_dom_u[tuple(perm2)]+=1\n",
    "                who_do_u_dom[tuple(perm1)].append(tuple(perm2))\n",
    "\n",
    "        selected = 0\n",
    "        front_num=0\n",
    "        while (selected != len(self.population)):\n",
    "            for perm in self.population:\n",
    "                if(how_many_many_dom_u[tuple(perm)]==0):\n",
    "                    pareto_fronts[front_num].append(perm)\n",
    "                    how_many_many_dom_u[tuple(perm)]=-1\n",
    "                    selected+=1\n",
    "            for key in pareto_fronts[front_num]:\n",
    "                for perm in who_do_u_dom[tuple(key)]:\n",
    "                    how_many_many_dom_u[tuple(perm)]-=1 \n",
    "            front_num+=1\n",
    "        return pareto_fronts\n",
    "\n",
    "    def step(self):\n",
    "        pareto_fronts = self.pareto_fronts()\n",
    "        taken=0\n",
    "        self.population=[]\n",
    "        for front in pareto_fronts:\n",
    "            for perm in front:\n",
    "                if(taken==self.pop_size//2):\n",
    "                    break\n",
    "                else:\n",
    "                    self.population.append(perm)\n",
    "                    taken+=1\n",
    "        self.population=np.array(self.population)\n",
    "        self.gen_kids()\n",
    "        self.mutation()\n",
    "        self.population = np.vstack((self.population,self.children))\n",
    "\n",
    "# reserved * ilość funkcji < popsize//2  \n",
    "model = genetic_tsp_pareto(eval1,100,1000,1)\n",
    "for i in range(1000):\n",
    "    model.step()\n",
    "\n",
    "min_dist=np.inf\n",
    "min_dist_perm=0\n",
    "min_cost=np.inf\n",
    "min_cost_perm=0\n",
    "min_norm=np.inf\n",
    "min_norm_perm=0\n",
    "wazne = model.pareto_fronts()[0]\n",
    "wazne_sorted = sorted(wazne, key=lambda perm: model.eval_fun(list(perm))[0])\n",
    "print(len(wazne))\n",
    "for perm in wazne_sorted:\n",
    "    vec2= eval1(perm)\n",
    "    if(vec2[0]<min_dist):\n",
    "        min_dist=vec2[0]\n",
    "        min_dist_perm=perm\n",
    "    if(vec2[1]<min_cost):\n",
    "        min_cost=vec2[1]\n",
    "        min_cost_perm=perm\n",
    "    if(np.linalg.norm(vec2)<min_norm):\n",
    "        min_norm=np.linalg.norm(vec2)\n",
    "        min_norm_perm=perm\n",
    "    print(f'dist: {vec2[0]}   cost: {vec2[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zbiór rozwiązań niezdominowanaych długości 33----------------------------\n",
      "dist: 77221   cost: 162046\n",
      "dist: 79732   cost: 161755\n",
      "dist: 81538   cost: 152974\n",
      "dist: 81880   cost: 152677\n",
      "dist: 81941   cost: 148257\n",
      "dist: 83084   cost: 130441\n",
      "dist: 83496   cost: 126699\n",
      "dist: 83927   cost: 125974\n",
      "dist: 85496   cost: 123432\n",
      "dist: 87589   cost: 114793\n",
      "dist: 89040   cost: 107218\n",
      "dist: 100722   cost: 105838\n",
      "dist: 100741   cost: 105080\n",
      "dist: 103298   cost: 104642\n",
      "dist: 103310   cost: 104489\n",
      "dist: 103629   cost: 101975\n",
      "dist: 105242   cost: 98443\n",
      "dist: 107560   cost: 97859\n",
      "dist: 107644   cost: 92014\n",
      "dist: 108478   cost: 89130\n",
      "dist: 110672   cost: 88981\n",
      "dist: 116563   cost: 88935\n",
      "dist: 119935   cost: 88710\n",
      "dist: 122291   cost: 87938\n",
      "dist: 124503   cost: 87070\n",
      "dist: 128051   cost: 86980\n",
      "dist: 128327   cost: 83955\n",
      "dist: 144441   cost: 80251\n",
      "dist: 159675   cost: 80178\n",
      "dist: 159699   cost: 77676\n",
      "dist: 168803   cost: 76854\n",
      "dist: 174106   cost: 76773\n",
      "dist: 176283   cost: 74185\n"
     ]
    }
   ],
   "source": [
    "print(f'zbiór rozwiązań niezdominowanaych długości {len(wazne)}----------------------------')\n",
    "for perm in wazne_sorted:\n",
    "    vec2= eval1(perm)\n",
    "    if(vec2[0]<min_dist):\n",
    "        min_dist=vec2[0]\n",
    "        min_dist_perm=perm\n",
    "    if(vec2[1]<min_cost):\n",
    "        min_cost=vec2[1]\n",
    "        min_cost_perm=perm\n",
    "    if(np.linalg.norm(vec2)<min_norm):\n",
    "        min_norm=np.linalg.norm(vec2)\n",
    "        min_norm_perm=perm\n",
    "    print(f'dist: {vec2[0]}   cost: {vec2[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wnioski i podsumowanie wyników"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki chociaż nie są zadowalające w sensie uzysknaych wartości są  w porównaniu do tych osiągniętych które są w odpowiedziach, generują jednak zawsze zbiór nie zdominowanych w swojej populacji rozwiązań, czyli algorytm daje nam pewną gamę rozwiazań z czego każdy jest pewnym optimum, a o to nam chodziło"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W porównaniu do pozostałych algorytmów podział pareto wyróżnił się tym że stawiał na róznorodność bardziej niż szukanie poszczególnych optimów funkcji.\n",
    "Algorytm zarezerwowanych miejsc natomiast pomimo swojej umiarkowanie szybkiej zbiezności do minimów lokalnych osiągną znacząoco lepsze ptima poszczególnych funkcji, przez co mozna zakładać że pomimo że zbiór rozwiązań niezależnych w tamtym przypadku nie był by zbyt duży to był by on 'optymalniejszy' tzn zdominował by znaczącą część wygenerowanych w końcowym algorytmie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z czego mogą wynikać tak słabe szukanie optimów poszczególnych funkcji?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tak jak już pisałem w rozkładzie pareto najbardziej ceniona była różnorodność, przez co do danego optimum lokalnego dążyło mniej osobników więc ciężko było żeby losowo trafić na optymalizującą mutacje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspektywy Rozwoju"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z analizy poprzedniego rozwiązania można wywnioskować że rezerwacja miejsc była dobrym sposobem na pogłębianie ekstremów, by ulepszyć algorytm oparty na rozkładzie pareto, można by połączyć oba rozwiązania. To znaczy dalej promować różnorodność jednak tym razem mieć również zarezerwowane miejsca dla kilku pierwszych optimów każdej funkcji celu, by dla każdej z nich znalezinoe minimum w rozwiązaniach było jak kolwiek wiarygodne. Nastepnie można wprowadzić pewną modyfikacje 'warunek stop-u' jeżeli przez iles generacji nie udało nam się poprawić optimum danej funckji można rezerwacje miejsc przerzucić z optium funkcji celu do np. rozwiązań 2 względem tej funkcji niezależnego rozwiązania, itd aż wszystkie rozwiązania niezalezne 'znajdą swoje optima' bądź przestaną być niezależne."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
